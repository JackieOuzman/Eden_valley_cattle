---
title: "Eden Valley Cattle VF importing and cleaning data"
author: "Jackie Ouzman"
date: "18 July 2019"
output: html_document
---

# SAMDBNRMB: Applying virtual fencing for NRM outcomes in SA
** Project details: **

Start Date	6/05/2019

End Date 31/08/2019

Team Member:
Rick Llewellyn (4 days)
Damian Mowat (20 days)
Willie Shoobridge (10 days)
Jackie Ouzman (10 days)


Jim Lea Research Technician wk  02 67761419 mob  0407137466

## Aim of project:
Use virtual fencing collar on cattle to protect watercourse within a paddock. Over 8 weeks observe the reduced grazing pressure in the exclusion zone.

## Background
### site: Eden Valley
### Animals:
### Collar: make and model used

https://www.eshepherd.com/client/login
Login:  Jim.Lea@csiro.au
Password: cs1roP@ss




```{r setup install packages, include=FALSE}
library(tidyverse)
library(dplyr)
library(lubridate)
library(readxl)

library(ggplot2)
library(readr)
library(sp)
library(biogeo)
library(stringr)
library(rgdal)
library(sf)

library(gganimate)
library(png)
library(gifski)

knitr::opts_chunk$set(include = FALSE)
```

## The first steps is to bring in the data files

After the files are downloaded from the collar they get 'converted'
Jim Lea from Armidale does this.
The files get a folder with a date and within this is a series of csv files.
One file for each collar each day.

At the monmnet the data (for the older collars are located here:

W:/VF/Eden_Valley/logged_VF_data/collar logs_download2/

# step 1 create function to import the data.
This function attaches the collar name to the file
creates a sensiable time column and writes the files out to another directory.
Note this could be changes if you are working on a vitrual machine.

```{r setting up functions to import the data, eval=FALSE, include=FALSE}
read_csv_FUN <- function(file ){
  the_data <- read_csv(file, col_types = cols(value = col_character()))
}


import_function <- function(mydir){
  
  myfiles = list.files(path=mydir, pattern="*.csv", full.names=TRUE)
  #1a########### Get file names
  filenames <- myfiles
  collars <- str_extract(myfiles, "[a-z]+\\d{1,6}")
  
  #1b########## Get length of each csv
  file_lengths <- unlist(lapply(lapply(filenames, read_csv), nrow))
  #file_lengths
  #1c########## Repeat collars using lengths
  file_names <- rep(collars,file_lengths)
  
  #1d######### Create table
  tbl <- lapply(filenames, read_csv_FUN) %>% #this call the function read_csv_FUN I made outside this import_function
    bind_rows()
  #1e######### Combine file_names and tbl
  VF <- cbind(tbl, collar_ID = file_names)
  #glimpse(VF)
  
  ################## Step 2 extra clms for  raw logged data   ##############################################
  VF <- VF %>% 
    separate(collar_ID,into =  c("collar", "date"),  sep = "_", remove = FALSE ) %>% 
    mutate(hms = hms::as.hms(time, tz="GMT"),
           date= date(time),
           month = month(time),
           day = day(time))
  write_csv(VF, path = paste0("W:/VF/Eden_Valley/logged_VF_data/download2_R_output/", "VF_", mydir, ".csv")) 
}


```

# step 2 Use the function to import the data and combine
It would be better if this was a loop.


```{r use function bring n data, eval=FALSE, include=FALSE}
##### Use the function to bring in data for one day that is specified ######
VF_20190607 <- import_function("20190607")
VF_20190606 <- import_function("20190606")
VF_20190605 <- import_function("20190605")
VF_20190604 <- import_function("20190604")
VF_20190603 <- import_function("20190603")
VF_20190602 <- import_function("20190602") #not written r bind 
VF_20190601 <- import_function("20190601")
VF_20190531 <- import_function("20190531")
VF_20190530 <- import_function("20190530")
VF_20190529 <- import_function("20190529")
VF_20190528 <- import_function("20190528")
VF_20190527 <- import_function("20190527")
VF_20190526 <- import_function("20190526")
VF_20190525 <- import_function("20190525")
VF_20190524 <- import_function("20190524")
VF_20190523 <- import_function("20190523")
VF_20190522 <- import_function("20190522")
VF_20190521 <- import_function("20190521")
VF_20190520 <- import_function("20190520")
VF_20190519 <- import_function("20190519")
VF_20190518 <- import_function("20190518")
VF_20190517 <- import_function("20190517")

VF_week1 <- rbind(VF_20190517, VF_20190518, VF_20190519,
                  VF_20190520, VF_20190521, VF_20190522, VF_20190523)
VF_week2 <- rbind(VF_20190524, VF_20190525, VF_20190526,
                  VF_20190527, VF_20190528, VF_20190529, VF_20190530)
VF_week3 <- rbind(VF_20190531, VF_20190601, 
                  VF_20190602, #not written ? not sure why
                  VF_20190603, VF_20190604, VF_20190605, VF_20190606)

write_csv(VF_week1, path = paste0("W:/VF/Eden_Valley/logged_VF_data/download2_R_output/", "VF_week1.csv"))
write_csv(VF_week2, path = paste0("W:/VF/Eden_Valley/logged_VF_data/download2_R_output/", "VF_week2.csv"))
write_csv(VF_week3, path = paste0("W:/VF/Eden_Valley/logged_VF_data/download2_R_output/", "VF_week3.csv"))
glimpse(VF_20190607)

```

# These steps are quite long
A short cut and a way to improve running R would be just to start here with the merged files.
Note that there is an important step that might need to be revisted.

I am just using InclusionBorder_m data and setting values to number.
If I need to look at the other data types I might need to revist this step.
```{r import merged week1 - 3 files}

#VF_week1 <- read_csv("//172.20.104.21/OSM_Mel_ces_spatiotemp_scratch/Users/Jackie/VF_week1.csv")
#VF_week2 <- read_csv("//172.20.104.21/OSM_Mel_ces_spatiotemp_scratch/Users/Jackie/VF_week2.csv")
#VF_week3 <- read_csv("//172.20.104.21/OSM_Mel_ces_spatiotemp_scratch/Users/Jackie/VF_week3.csv")

##########       Merge this all togther   ##########       
#VF_week1_2_3 <- rbind(VF_week1, VF_week2, VF_week3)
##########       ensure the column value is a number - double    ##########
#VF_week1_2_3_InclusionBord <- filter(VF_week1_2_3, event == "InclusionBorder_m") %>%   
#  mutate( value = as.double(value))


 #########    Remove the NA   ##########

#VF_week1_2_3_InclusionBord <- VF_week1_2_3_InclusionBord %>% filter(!is.na(lat) | !is.na(lon))

#summary(VF_week1_2_3_InclusionBord$lat)
#summary(VF_week1_2_3_InclusionBord$lon)

#write_csv(VF_week1_2_3_InclusionBord, path = paste0("W:/VF/Eden_Valley/logged_VF_data/download2_R_output/", #"VF_week1_2_3_InclusionBord.csv"))

VF_week1_2_3_InclusionBord <- read_csv("//172.20.104.21/OSM_Mel_ces_spatiotemp_scratch/Users/Jackie/VF_week1_2_3_InclusionBord.csv")

```


#3.Do projections
 

#https://spatialreference.org/ref/epsg/gda94-mga-zone-56/
#epsg projection 28356

```{r project data}

mapCRS <- CRS("+init=epsg:28354")     # 28355 = GDA_1994_MGA_Zone_54
wgs84CRS <- CRS("+init=epsg:4326")   # 4326 WGS 84 - assumed for input lats and longs

####################  convert lat and longs to x and Y     ##########################################
coordinates(VF_week1_2_3_InclusionBord) <- ~ lon + lat
proj4string(VF_week1_2_3_InclusionBord) <- wgs84CRS   # assume input lat and longs are WGS84
#make new object_1
VF_week1_2_3_InclusionBord_1 <- spTransform(VF_week1_2_3_InclusionBord, mapCRS)
#make new df_1
head(VF_week1_2_3_InclusionBord_1,3)
VF_week1_2_3_InclusionBord = as.data.frame(VF_week1_2_3_InclusionBord_1) #this has the new coordinates projected !YES!!
#make new df with point x and point y
VF_week1_2_3_InclusionBord <- mutate(VF_week1_2_3_InclusionBord,POINT_X = lon,  POINT_Y = lat )
head(VF_week1_2_3_InclusionBord)

```



# Time to fix up the data 
The first task with this is to remove the data points that are not in the paddock.



I can use the clip(from sf) function but I need to convert it into an sf object 
1) turn df data into sf object to do spatial analysis on.

```{r convert df to sf object}

### turn my data into 'shapefile' format - not sure i need this step 

mapCRS <- CRS("+init=epsg:28354")     # 28355 = GDA_1994_MGA_Zone_54

VF_week1_2_3_InclusionBord_spatial <- st_as_sf(VF_week1_2_3_InclusionBord, coords = c("POINT_X", "POINT_Y"), crs = mapCRS)
glimpse(VF_week1_2_3_InclusionBord_spatial)




```


2)Bring in the paddock and VF boundaries and plot it

```{r bring in the paddock boundaries and VF}
###bring in the polygon file
eden_valley <- st_read(
  "W:/VF/Eden_Valley/VF_Boundary/EdenValley_site1GDA_a.shp")

fence1 <- st_read(
  "W:/VF/Eden_Valley/VF_Boundary/Fence1.shx")
fence2 <- st_read(
  "W:/VF/Eden_Valley/VF_Boundary/Fence2.shx")
fence3 <- st_read(
  "W:/VF/Eden_Valley/VF_Boundary/Fence3.shx")
fence4 <- st_read(
  "W:/VF/Eden_Valley/VF_Boundary/Fence4a.shx")
fence5 <- st_read(
  "W:/VF/Eden_Valley/VF_Boundary/Fence_hotwire_rd_side_clipped.shx")


ggplot()+
  geom_sf(data = eden_valley, size = 2 , colour = "black", fill=NA)+
  geom_sf(data = fence1, size = 1 , colour = "black")+
  geom_sf(data = fence2, size = 1 , colour = "grey")+
  geom_sf(data = fence3, size = 1 , colour = "blue")+
  geom_sf(data = fence4, size = 1 , colour = "red")+
  geom_sf(data = fence5, size = 1 , colour = "pink")+
  coord_sf()

```


 3) use the st intersection function to clip the data to the paddock boundaries.

```{r clip }
VF_week1_2_3_InclusionBord_clip <- st_intersection(VF_week1_2_3_InclusionBord_spatial, eden_valley)
head(VF_week1_2_3_InclusionBord_clip, 3)
```

Get my 'clipped spatial data' back to df

```{r back to df}



head(VF_week1_2_3_InclusionBord_clip ,3)
df_VF_week1_2_3_InclusionBord_clip <- data.frame(VF_week1_2_3_InclusionBord_clip)
df_VF_week1_2_3_InclusionBord_clip <- mutate(df_VF_week1_2_3_InclusionBord_clip,
                                             POINT_X = lon,  POINT_Y = lat )
head(df_VF_week1_2_3_InclusionBord_clip ,3)

df_VF_week1_2_3_InclusionBord_c <- select(df_VF_week1_2_3_InclusionBord_clip,
                                             -geometry,
                                             -OID_,
                                             -Name,
                                             -FolderPath, 
                                             -SymbolID, 
                                             -AltMode, 
                                             -Base, 
                                             -Clamped, 
                                             -Extruded, 
                                             -Snippet, 
                                             -PopupInfo, 
                                             -Shape_Leng,
                                             -Shape_Area,
                                             -lon,
                                             -lat)

head(df_VF_week1_2_3_InclusionBord_c ,3)

```
# Time to fix up the start date of trial 
The first task with this is to remove the data points that are pre trial.

```{r remove pre trial values}
#############  Remove Pre trial readings ##############

df_VF_week1_2_3_InclusionBord_c <- filter(df_VF_week1_2_3_InclusionBord_c, time > as_datetime('2019-05-20 12:30:00', tz="GMT"))

```

# Create new data column for animal number and iceqube
The same animals were used for the lenghth of the trial, but at times the collars were changed.
I need to assign animal number to correct collars.
This log was made by Jim and Damian.

"\\FSSA2-ADL\clw-share1\Microlab\VF\Eden_Valley\logged_VF_data\collar log record complete.xlsx"
The actual times for collar strating and stopping are not included in all of the log entries.
Now to find them!

```{r animal_ID}

test <- filter(df_VF_week1_2_3_InclusionBord_c,collar_ID == "ac220" ) 
min(as_datetime(test$time, tz="GMT")) 
max(as_datetime(test$time, tz="GMT"))

df_VF_week1_2_3_InclusionBord_c_test <- mutate(df_VF_week1_2_3_InclusionBord_c,
                                             animal_ID = case_when(
                                               collar_ID == "ac138" ~ "Q46",
                                               collar_ID == "ac187" ~ "Q36",
                                               collar_ID == "ac204"  &
                                                 between(time, as_datetime('2019-05-20 12:30:00', tz="GMT"),
                                                         as_datetime('2019-05-30 13:26:00', tz="GMT")) ~ "Q108",
                                               #collar_ID == "xxxx"  &
                                               #  between(time, as_datetime('2019-xx-xx xx:xx:00', tz="GMT"),
                                               #          as_datetime('2019-xx-xx xx:xx:00', tz="GMT")) ~ "Q108",
                                               collar_ID == "ac207" ~ "Q42",
                                               collar_ID == "ac212" ~ "Q29",
                                               collar_ID == "ac213" &
                                                 between(time, as_datetime('2019-05-20 12:30:00', tz="GMT"),
                                                         as_datetime('2019-05-28 06:44:00', tz="GMT")) ~ "Q47",
                                               collar_ID == "ac320" &
                                                 between(time, as_datetime('2019-05-28 11:01:00', tz="GMT"),
                                                         as_datetime('2019-06-06 17:27:00', tz="GMT")) ~ "Q47" ,
                                               collar_ID == "ac217" ~ "Q27",
                                               collar_ID == "ac218" ~ "Q2",
                                               collar_ID == "ac219" &
                                                 between(time, as_datetime('2019-05-20 12:32:03', tz="GMT"),
                                                         as_datetime('2019-05-25 11:10:00', tz="GMT"))~ "Q10",
                                               collar_ID == "ac220" &
                                                 between(time, as_datetime('2019-05-25 11:01:00', tz="GMT"),
                                                         as_datetime('2019-06-06 17:27:18', tz="GMT"))~ "Q10",
                                               collar_ID == "ac325" ~ "Q9",
                                               collar_ID == "ac328" ~ "Q109",
                                               collar_ID == "ac331" ~ "Q51",
                                               collar_ID == "ad1945" ~ "Q28",
                                               collar_ID == "ad2042" ~ "Q26",
                                               collar_ID == "ad2043" ~ "Q75",
                                               collar_ID == "ad3374" ~ "Q11",
                                               collar_ID == "ad3396"  &
                                                 between(time, as_datetime('2019-05-20 12:30:00', tz="GMT"),
                                                         as_datetime('2019-05-27 16:19:00', tz="GMT"))~ "Q45",
                                               collar_ID == "ac209"  &
                                                 between(time, as_datetime('2019-05-28 11:11:00', tz="GMT"),
                                                         as_datetime('2019-06-06 17:00:00', tz="GMT"))~ "Q45",
                                               collar_ID == "ad3471" ~ "Q15",
                                               collar_ID == "ad3502" ~ "Q8",
                                               collar_ID == "ad3925" ~ "Q110",
                                               TRUE ~ "NA"))


```




# 4. Now I need to view each day collar to work out when the collars failed.
I have done this using the filter function and then check out the distance from fence.

```{r inspect data to view quaility}
dim(df_VF_week1_2_3_InclusionBord_c_test)
Inclusion_20_05_2019 <- df_VF_week1_2_3_InclusionBord_c_test %>% 
  filter(date == "2019-05-20") 

  ggplot(Inclusion_20_05_2019, aes(x = hms, y = value, colour = collar))+
  geom_point()+
  facet_wrap(.~collar)+
  geom_hline(yintercept = 0)+
  theme(axis.text.x=element_text(angle=90,hjust=1),
        legend.position = "none")+
  labs(title= "weekX 2019-xx-xx",
       x= "Time of day",
       y = "Distance (m) from VF")


ggplot() +
  geom_sf(data = eden_valley, color = "black", fill = NA) +
  geom_sf(data = fence1, color = "grey") +
  geom_sf(data = fence2, color = "grey") +
  geom_point(data = Inclusion_20_05_2019, aes(POINT_X, POINT_Y,colour = collar), inherit.aes = FALSE) +
  facet_wrap(.~collar)+
  theme_bw()+
  theme(legend.position = "none",
        axis.text.x=element_text(angle=90,hjust=1))


  ggplot(Inclusion_20_05_2019, aes(x = POINT_X, y = POINT_Y))+
  geom_point()+
  facet_wrap(.~collar)+
  labs(title= "week1 2019-05-xx",
       x= "POINT_X",
       y = "POINT_Y")+
  theme(axis.text.x=element_text(angle=90,hjust=1),
        legend.position = "none")
```



Remove week one odd readings.
I am doing this by creating a new data column called chuck.
I assign a value of 1 if I intent to remove it and a value 2 if I want to retain it.
ac209 20/5/2019 
ac207 23/5/2019 07:00-10:00
ac213 23/5/2019 07:00 -10:00



```{r filter out week 1 readings}
################################################################################################################
###################      Filter out rows of data for 20/5/2019 ac209  #################################
VF_week1_2_3_InclusionBord <-  mutate(VF_week1_2_3_InclusionBord,
                                      chuck = case_when(
                                        collar_ID == "ac209" & 
                                          date == as_datetime('2019-05-20') ~ 1,
                                                  TRUE ~ 2))
#check_week1 <- filter(VF_week1_2_3_InclusionBord,
                      #chuck == 1)
#dim(check_week1)

################################################################################################################
###################      Filter out rows of data for 23/5/2019 ac207 and ac213 #################################
################### This creates a clm called chuck for the data to be discarded

################ for ac207 between 08:00 to 09:00 on the 23/5/2019 ####

VF_week1_2_3_InclusionBord <-  mutate(VF_week1_2_3_InclusionBord,
                               chuck = case_when(
                               collar_ID == "ac207" & 
                               between(time, as_datetime('2019-05-23 07:00:00', tz="GMT"),
                               as_datetime('2019-05-23 10:00:00', tz="GMT")) ~1,
                               TRUE ~ chuck))

#check_week1 <- filter(VF_week1_2_3_InclusionBord, chuck == 1)
#dim(check_week1)
################ for ac213 between 08:00 to 09:00 on the 23/5/2019 ####

VF_week1_2_3_InclusionBord <-  mutate(VF_week1_2_3_InclusionBord,
                                      chuck = case_when(
                                        collar_ID == "ac213" & 
                                          between(time, as_datetime('2019-05-23 07:00:00', tz="GMT"),
                                                  as_datetime('2019-05-23 10:00:00', tz="GMT")) ~1,
                                        TRUE ~ chuck))


#check_week1 <- filter(VF_week1_InclusionBord_VF1,chuck == 1)
#summary(check_week1)
#dim(check_week1)

```

Remove week two odd readings.
I am doing this by creating a new data column called chuck.
I assign a value of 1 if I intent to remove it and a value 2 if I want to retain it.
To chuck:
ac219 from 15:00 onwards      on the  24/5/2019
ac219                         on the  25/5/2019 
ac220  before  11:00  on the  on the 25/5/2019 
ad3925 before 20:30 to 22:30  on the  25/5/2019
ad3396 between 1500-23:00     on the  27/5/2019
ad3925 between 19:30-20:30     on the  27/5/2019
ac320 between 11:00-11:30     on the  28/5/2019
ac209 between 11:00-11:30     on the  28/5/2019
ac211 between 11:00-11:30     on the  28/5/2019
ad3396 between 10:00-12:30     on the  28/5/2019
ac211 between whole day     on the  28/5/2019
ad2042 value >3000 on the 28/5/2019
ac333 06:00-14:00 on the 30/5/2019







```{r filter out week 2 readings}
################ for ac219 from 15:00  on the 24/5/2019 and 25/5/2019####

VF_week1_2_3_InclusionBord <-  mutate(VF_week1_2_3_InclusionBord,
                                      chuck = case_when(
                                        collar_ID == "ac219" & 
                                          between(time, as_datetime('2019-05-24 15:00:00', tz="GMT"),
                                               as_datetime('2019-05-24 24:00:00', tz="GMT")) ~1,
                                        TRUE ~ chuck))
VF_week1_2_3_InclusionBord <-  mutate(VF_week1_2_3_InclusionBord,
                                      chuck = case_when(
                                        collar_ID == "ac219" & 
                                          date == as_datetime('2019-05-25') ~ 1,
                                        TRUE ~ chuck))

############### for ac220 before 11:00  on the  25/5/2019####

VF_week1_2_3_InclusionBord <-  mutate(VF_week1_2_3_InclusionBord,
                                  chuck = case_when(
                                    collar_ID == "ac220" & 
                                      time < as_datetime('2019-05-25 11:00:00', tz="GMT") ~ 1,
                                    TRUE ~ chuck))

############### for ad3925 before 20:30 to 21:30  on the  25/5/2019####

VF_week1_2_3_InclusionBord <-  mutate(VF_week1_2_3_InclusionBord,
                                   chuck = case_when(
                                     collar_ID == "ad3925" & 
                                       between(time, as_datetime('2019-05-25 20:30:00', tz="GMT"),
                                               as_datetime('2019-05-25 22:30:00', tz="GMT")) ~1,
                                     TRUE ~ chuck))

############### for ad3396 between 1500-23:00  on the  27/5/2019####

VF_week1_2_3_InclusionBord <-  mutate(VF_week1_2_3_InclusionBord,
                                      chuck = case_when(
                                        collar_ID == "ad3396" & 
                                          between(time, as_datetime('2019-05-27 15:00:00', tz="GMT"),
                                                  as_datetime('2019-05-27 23:00:00', tz="GMT")) ~1,
                                        TRUE ~ chuck))



############### for ad3925 between 1500-23:00  on the  27/5/2019####
#table(VF_week2_InclusionBord1$collar_ID)
VF_week1_2_3_InclusionBord <-  mutate(VF_week1_2_3_InclusionBord,
                                   chuck = case_when(
                                     collar_ID == "ad3925" & 
                                       between(time, as_datetime('2019-05-27 19:30:00', tz="GMT"),
                                               as_datetime('2019-05-27 20:30:00', tz="GMT")) ~1,
                                     TRUE ~ chuck))




############### for ac320 between 10:00-11:45  on the  28/5/2019####

VF_week1_2_3_InclusionBord <-  mutate(VF_week1_2_3_InclusionBord,
                                   chuck = case_when(
                                     collar_ID == "ac320" & 
                                       between(time, as_datetime('2019-05-28 11:00:00', tz="GMT"),
                                               as_datetime('2019-05-28 11:30:00', tz="GMT")) ~1,
                                     TRUE ~ chuck))



############### for ac209 between 10:00-11:45  on the  28/5/2019####

VF_week1_2_3_InclusionBord <-  mutate(VF_week1_2_3_InclusionBord,
                                   chuck = case_when(
                                     collar_ID == "ac209" & 
                                       between(time, as_datetime('2019-05-28 11:00:00', tz="GMT"),
                                               as_datetime('2019-05-28 11:30:00', tz="GMT")) ~1,
                                     TRUE ~ chuck))



############### for ac211 between 10:00-11:45  on the  28/5/2019####

VF_week1_2_3_InclusionBord <-  mutate(VF_week1_2_3_InclusionBord,
                                   chuck = case_when(
                                     collar_ID == "ac211" & 
                                       between(time, as_datetime('2019-05-28 11:00:00', tz="GMT"),
                                               as_datetime('2019-05-28 11:30:00', tz="GMT")) ~1,
                                     TRUE ~ chuck))



############### for ad3396 between 10:00-11:45  on the  28/5/2019####

VF_week1_2_3_InclusionBord <-  mutate(VF_week1_2_3_InclusionBord,
                                   chuck = case_when(
                                     collar_ID == "ad3396" & 
                                       between(time, as_datetime('2019-05-28 10:00:00', tz="GMT"),
                                               as_datetime('2019-05-28 12:30:00', tz="GMT")) ~1,
                                     TRUE ~ chuck))


############### for ac211 between 10:00-11:45  on the  28/5/2019####
VF_week1_2_3_InclusionBord <-  mutate(VF_week1_2_3_InclusionBord,
                                      chuck = case_when(
                                        collar_ID == "ac211" & 
                                          date == as_datetime('2019-05-28') ~ 1,
                                        TRUE ~ chuck))


############### for ad2042 for values greater than 3000meter from VF  on the  28/5/2019####
VF_week1_2_3_InclusionBord <-  mutate(VF_week1_2_3_InclusionBord,
                                   chuck = case_when(
                                     collar_ID == "ad2042" & 
                                       value > 3000  ~ 1,
                                     TRUE ~ chuck))


############### for ac333   on the 06:00 - 14:00 30/5/2019####
#table(VF_week2_InclusionBord1$collar_ID)
VF_week1_2_3_InclusionBord <-  mutate(VF_week1_2_3_InclusionBord,
                                   chuck = case_when(
                                     collar_ID == "ac333" & 
                                       between(time, as_datetime('2019-05-30 06:00:00', tz="GMT"),
                                               as_datetime('2019-05-30 14:00:00', tz="GMT")) ~1,
                                     TRUE ~ chuck))

check_week2 <- filter(VF_week1_2_3_InclusionBord,
                      chuck == 1)
dim(check_week2)



```

Now remove the rows we dont want
```{r filtering out the rows}

VF_week1_2_3_InclusionBord <- filter(VF_week1_2_3_InclusionBord, chuck == 2)

VF_week1_2_3_InclusionBord <- mutate(VF_week1_2_3_InclusionBord,
                                    hour= hour(time))

```

Check out what we have done??
```{r}
VF_week1_2_3_InclusionBord %>% 
  filter(date == "2019-05-20") %>% 
  ggplot(aes(x = POINT_X, y = POINT_Y, colour = hour))+
  geom_point()+
  facet_wrap(.~collar)+
  labs(title= "week1 2019-05-xx",
       x= "POINT_X",
       y = "POINT_Y")+
  theme(axis.text.x=element_text(angle=90,hjust=1),
        legend.position = "none")
```








  #) clip function

```{r clip }
VF_week1_2_3_InclusionBord_clip <- st_intersection(VF_week1_2_3_InclusionBord_spatial, eden_valley)
head(VF_week1_2_3_InclusionBord_clip)
```


Plot

```{r might be too big?}

##subset the data so I can work out what I am doing 
VF_week1_2_3_InclusionBord_clip_subset <- filter(VF_week1_2_3_InclusionBord_clip, 
                                          between(time, as_datetime('2019-05-28 08:00:00', tz="GMT"),
                                                        as_datetime('2019-05-28 09:30:00', tz="GMT"))) 




ggplot()+
    geom_sf(data = eden_valley, size = 2 , colour = "black", fill=NA)+
    geom_sf(data = fence1, size = 1 , colour = "black")+
    geom_sf(data = fence2, size = 1 , colour = "grey")+
    geom_sf(data = fence3, size = 1 , colour = "blue")+
    geom_sf(data = fence4, size = 1 , colour = "red")+
    geom_sf(data = fence5, size = 1 , colour = "pink")+
    geom_sf(data = VF_week1_2_3_InclusionBord_clip_subset, size = 1 , colour = "black")
  coord_sf()
```




Make an annimation

```{r annimation}
###can split this up a bit and add in larger data set
##subset data to messing about

head(df_VF_week1_2_3_InclusionBord_clip ,3)

animmation_data <- df_VF_week1_2_3_InclusionBord_clip %>% 
  filter(date == "2019-05-20") 
#write.csv(animmation_data, "animmation_data.csv")

head(animmation_data,3)

p4a <- ggplot() +
  geom_sf(data = eden_valley, color = "black", fill = NA) +
  geom_sf(data = fence1, color = "grey") +
  geom_sf(data = fence2, color = "grey") +
  geom_sf(data = fence3, color = "grey") +
  geom_sf(data = fence4, color = "grey") +
  geom_sf(data = fence5, color = "grey") +
  geom_point(data = animmation_data, aes(POINT_X, POINT_Y,colour = collar), inherit.aes = FALSE) +
  #facet_wrap(.~collar)+
  theme_bw()+
  theme(legend.position = "none",
        axis.text.x=element_text(angle=90,hjust=1))

  
p4a  
 
p4b <- p4a +
  labs( title =   'Date:  {format(as_datetime(frame_time, "%b %e"), tz="GMT")}',
        subtitle = 'Hour: {format(as_datetime(frame_time, "%H"), tz="GMT")}',
       caption = "Frame {frame} of {nframes} ({progress * 100}%)") +
  transition_time(time) +
  shadow_wake(0.3)

animation_20th <- animate(p4b, duration = 30) 

anim_save(animation_20th, animation_20th)
  
  
```
Create a new colum for the animal number and work out when to change it over



